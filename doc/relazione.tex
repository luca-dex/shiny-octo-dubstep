\documentclass[11pt,a4paper,appendixprefix=true,numbers=noenddot]{scrreprt}

\usepackage[hidelinks, bookmarks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{minted}
\usepackage{amsmath, amsfonts}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{parskip}
\usepackage{color}
\usepackage{pifont}

\usepackage{placeins}

\usepackage{algpseudocode}
\usepackage{framed}
\usepackage{url}

\newcommand{\yep}{\ding{51}}%
\newcommand{\nope}{\ding{55}}%

\newtheorem{teorema}{Teorema}
\newtheorem{definizione}{Definizione}
\newtheorem{lemma}[teorema]{Lemma}
\newtheorem{proposizione}[teorema]{Proposizione}
\newtheorem{proprieta}[teorema]{Proprietà}

\newcommand{\shellcmd}[1]{\\\indent\indent\texttt{\footnotesize\# #1}\\}

\author{L. De Sano, A. Donizetti}
\title{\textsc{FIC}: Fractal Image Compression}
\date{Settembre 2015}

\begin{document}
\maketitle

\tableofcontents

\chapter{Introduzione}

Con il termine ``Fractal image Compression'' si va ad indicare una famiglia di tecniche di compressione di immagini (o video) basate sulle proprietà matematiche dei frattali\cite{fisher}\cite{barnsley}. Tali metodi di compressione si rivelano sopra ogni altra cosa adatti a comprimere textures e immagini naturali, o, più in generale, immagini che sono caratterizzate da un elevato livello di \emph{self-similarity} (ovvero aventi delle parti che, al netto di rotazioni e ingrandimenti/riduzioni, somigliano ad altre parti dell'immagine).

La compressione di immagini tramite frattali (così come altre, più diffuse, ad esempio JPEG) appartiene a quel gruppo di tecniche di compressione \emph{lossy}, ovvero in cui la compressione dell'immagine avviene al costo di una perdita di informazione. Tuttavia, a differenza di quanto accade quando si utilizza uno dei metodi di compressione basati sui pixel (come JPEG, GIF o MPEG), nella compressione frattale nessuna parte dell'immagine viene effettivamente memorizzata. Ciò che viene memorizzato è invece la \emph{struttura interna} dell'immagine (ad esempio un indice di quali parti, effettuate le dovute trasformazioni, sono simili ad altre parti). 

Poiché nessun pixel dell'immagine originale viene memorizzato, la decompressione parte da una immagine di partenza, di colore qualsiasi e proporzioni pari a quella dell'immagine da ricostruire, e procede con la ricostruzione applicando iterativamente una mappa ricavata dalla struttura interna dell'immagine originale.

In questo documento tratteremo delle tecniche di compressione di immagini basate su frattali, iniziando con una panoramica teorica del loro funzionamento, proseguendo con la discussione di alcuni aspetti pratici e presentando una implementazione giocattolo realizzata in MATLAB, e concludendo infine con alcuni test che consentiranno di valutare praticità e \emph{performances} di una libreria di compressione basata su frattali, anche in confronto con altre tecniche di compressione \emph{lossy} maggiormente utilizzate.

\chapter{Aspetti teorici}

\section{Introduzione ai frattali}

\subsection*{Definizione matematica}

Iniziamo dando una definizione che sia il più possibile rigorosa del concetto di frattale, seguendo la trattazione delineata in \cite{barnsley}. Per fare questo, abbiamo bisogno di introdurre alcuni oggetti matematici, che verranno usati nel seguito. Come prima cosa:

\begin{definizione}
Uno spazio metrico $(\mathbf{X}, d)$ è uno spazio $\mathbf{X}$ a cui è associata una funzione $d: \mathbf{X} \times \mathbf{X} \rightarrow \mathbb{R}$, detta \emph{distanza}, che fornisce una misura della lontananza tra due punti $x, y \in \mathbf{X}$. $d$ deve soddisfare i seguenti assiomi:

\begin{itemize}
	\item $d(x,y) = d(y,x) \qquad \forall x, y \in \mathbf{X}$
	\item $0 < d(x,y) < \infty \qquad \forall x,y \in \mathbf{X}, x \neq y $
	\item $d(x,x) = 0 \qquad \forall x \in \mathbf{X} $
	\item $d(x, y) < d(x,z) + d(z, y) \quad \forall x, y, z, \in \mathbf{X} $
\end{itemize}
\end{definizione}

Sul concetto di spazio metrico può essere definita la nozione di \emph{compattezza}.

\begin{definizione}
Un sottoinsieme $S \subset \mathbf{X}$ di uno spazio metrico $(\mathbf{X}, d)$ si dice \emph{compatto} se ogni sequenza infinita $\{ x_n \}_{n=1}^{\infty}$ in S contiene una sottosequenza avente limite in $S$.
\end{definizione}

Si dimostra che un insieme è compatto se e solo se è chiuso e limitato. A questo punto è possibile introdurre il concetto di spazio $\mathcal{H}$:

\begin{definizione}
Sia $(\mathbf{X}, d)$ uno spazio metrico. Denotiamo con $\mathcal{H}(\mathbf{X})$ lo spazio i cui punti sono sottoinsiemi compatti di $\mathbf{X}$, escluso l'insieme vuoto.
\end{definizione}

\begin{definizione}
Dati due elementi $A, B \in \mathcal{H}(\mathbf{X})$, si definisce \emph{distanza secondo Hausdorff} tra $A$ e $B$ come
\[
h(A,B) = \max\{ d(A,B), ~ d(B,A) \}
\]

dove $d$ è la definizione di distanza per lo spazio $\mathbf{X}$.
\end{definizione}

Ci riferiamo ad $(\mathcal{H}(\mathbf{X}), h)$ come allo \textbf{spazio dei frattali}. Mantenendoci al massimo livello di generalità possibile, diciamo che ogni sottoinsieme di $(\mathcal{H}(\mathbf{X}), h)$ è un \textbf{frattale}. Nella successiva sottosezione daremo una breve lista di caratteristiche che ci aspettiamo di ritrovare in un oggetto che si vuole definire ``frattale'', fornendo così una definizione meno rigorosa ma più utile in campo appplicativo di questo elusivo concetto.

\subsection*{Caratteristiche intuitive}

Ci aspettiamo che un frattale sia un oggetto geometrico che si ripete nella sua forma, allo stesso modo, su diverse scale. Questo comportamento fa si che ingrandendo una sua qualsiasi componente, ciò che si ottiene è una figura simile all'originale. In linea di massima, si può dire che perché l'insieme $F \subseteq (\mathcal{H}(\mathbf{X}), h)$ sia considerato un frattale, dovrebbe godere di (alcune) delle seguenti proprietà:

\begin{itemize}
\item $F$ ha dettagli ad ogni scala d'ingrandimento;
\item $F$ gode di autosimilitudine (a qualunque scala si osservi, presenta sempre le stesse caratteristiche globali);
\item la dimensione frattale\footnote{La dimensione frattale è un rapporto che fornisce un indice statistico relativo a come varia la complessità di un frattale rispetto alla scala a cui viene misurato.} di $F$ è maggiore della sua dimensione topologica\footnote{Ad esempio in $\mathbb{R}^n$ è $n$.};
\item esiste un algoritmo relativamente semplice per costruire $F$.
\end{itemize}

Un esempio di oggetto geometrico secondo i principi di costruzione di un frattale e che rispetta le proprietà elencate è la curva di Koch. La costruzione comincia con una linea di lunghezza $1$ chiamata \emph{initiatior}. Da questa linea si rimuove il terzo centrale e lo si sostituisce con due linee della stessa lunghezza della parte rimossa. Questa nuova forma viene chiamata \emph{generator}. La prima parte della costruzione è mostrata in figura \ref{fig:k1}.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/koch1.png}
\caption{Initiator e generator per la curva di Koch}
\label{fig:k1}
\end{figure}

La regola può essere nuovamente applicata su ogni linea, così da andare a sostituirla ogni volta come fanno nel passaggio da \emph{initiator} a \emph{generator}. Il secondo livello è visibile in figura \ref{fig:k2}.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/koch2.png}
\caption{Livello 2 per la curva di Koch}
\label{fig:k2}
\end{figure}

\FloatBarrier

Una volta che la procedura è avviata può proseguire a piacimento. Il terzo e il quarto livello sono visibili nelle figure \ref{fig:k3} e \ref{fig:k4} rispettivamente.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/koch3.png}
\caption{Livello 3 per la curva di Koch}
\label{fig:k3}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/koch4.png}
\caption{Livello 4 per la curva di Koch}
\label{fig:k4}
\end{figure}



\section{Iterated Function Systems}

Uno strumento matematico che si rivelerà fondamentale nella fase di decompressione delle immagini trattate con un metodo di compressione frattale è quello degli \emph{Iterated Function Systems}, che andiamo per questo motivo a descrivere qui.

Senza eccedere in formalità, definiamo un \emph{Iterated Function System} (IFS) come una collezione di trasformazioni contrattive $\{w_i : \mathbb{R}^2 \rightarrow \mathbb{R}^2 \}_{i=1,\ldots, n}$ che mappa il piano su se stesso. Questa collezione di trasformazioni definisce una mappa 

\[
W(\cdot) = \bigcup_{i=1}^{n} w_i(\cdot)
\]

Tale mappa è applicata ad insiemi di punti, ed il risultato è definito in questa maniera: dato un insieme di punti $S \in \mathbb{R}^2$, calcoliamo $w_i(S)$ per ogni $i$ (ovvero produciamo $i$ copie ridotte di $S$), e poi calcoliamo l'unione dei risultati (ovvero, mettiamo insieme tutte le copie ridotte), ottenendo così un nuovo insieme $S' = W(S)$.

$W$ così definito è una mappa tra sottoinsiemi di $\mathbb{R}^2$ (che d'ora in avanti per noi saranno ``immagini''), e gode di due importanti (e rilevanti per la compressione frattale) proprietà, che andiamo ad enunciare senza dimostrazione.

\begin{proprieta}
Se tutte le $w_i$ sono contrattive, allora $W$ è contrattiva in uno spazio di sottoinsiemi del piano.
\end{proprieta}

\begin{proprieta}
Fissata una mappa $W$, esiste una immagine $x_W$, chiamata \emph{attrattore per $W$}, tale che
\begin{itemize}
\item $W(x_W) = x_W$
\item data una qualunque immagine di partenza $S_0$, vale che 
\[x_W \equiv \lim_{n \rightarrow \infty} W^{n}(S_0) \]
ovvero l'applicazione ripetuta per $n$ volte di $W$ porta ad ottenere $x_W$, per $n$ sufficientemente grande, ed indipendentemente dalla scelta dell'immagine di partenza.
\item $x_W$ è unica. Se una qualsiasi immagine $S$ soddisfa $W(S) = S$, allora $S$ è l'attrattore per $W$.
\end{itemize}
\end{proprieta}

La seconda di queste proprietà è nota come \emph{Contractive Mapping Fixed-Point Theorem}.

\section{Self-similarity nelle immagini}

\subsection*{Immagini come oggetti matematici}

Per poter applicare la teoria degli \emph{IFS} alle immagini come comunemente le intendiamo (ovvero, in sostanza, matrici di pixels rappresentati  da 1 byte -- \emph{greyscale} -- oppure più di uno -- es. RBG --), è necessario formalizzare in qualche modo il concetto di ``immagine digitale'', cercando di inserirlo in un contesto matematico che ci consenta di manipolarla utilizzando di strumenti messi a disposizione dall'algebra. Per semplicità, ci limiteremo qui a considerare le immagini in \emph{grayscale} (un singolo canale di colore, l'intensità indicata con un numero da 0 a 255).

Consideriamo un'immagine in scala di grigi, memorizzata come matrice di pixel, 1 byte per ogni pixel. Non è difficile immaginare di poter rappresentare tale immagine utilizzando una funzione $f: \mathbb{R}^2 \rightarrow  \{0, 1, \ldots, 255 \}$, in modo tale che ad ogni pixel alle coordinate $(x, y)$ sia fatto corrispondere un punto $(x, y)$ nel piano, al quale a sua volta viene associata un'altezza $z$, che corrisponde al valore di grigio del pixel in questione. 

Ad esempio, ad un'immagine con il primo pixel in basso a sinistra avente livello di grigio 177, viene fatta corrispondere una funzione $f$ che, per quanto riguarda quel preciso punto, avrà $f(0,0) = 177$. Effettuando questa operazione su tutti i pixel dell'immagine originale, è possibile definire completamente $f$ su tutta la parte del piano di nostro interesse (e, in genere, si riduce per convenzione l'immagine ad avere dominio 
$[0, 1]^2$). Nella figura qui sotto riportata si può vedere un esempio del risultato finale della procedura, applicata ad una immagine grayscale $128 \times 128$ pixels.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/lena-mash.pdf} 
\caption{lena grayscale, $128 \times 128$ pixels, trasformata in funzione $[0,1]^2 \rightarrow \{0,\ldots,255 \}$}
\end{figure}

La trasformazione descritta ci permette di ignorare l'aspetto ``visivo'' della modalità in cui una immagine è memorizzata, e ci consente di identificare una immagine con la funzione $f$ associata, su cui si andrà ad operare durante il procedimento di compressione.

\subsection*{Distanza tra due immagini}

Un secondo concetto che è necessario introdurre per poter operare sulle immagini durante il procedimento di compressione e decompressione è quello di ``distanza'' tra due immagini. La contrattività di una mappa $W$ (ovvero, intuitivamente, il fatto che essa rende le immagini più ``piccole'') può essere verificata solo se si ha a disposizione una qualche metrica sulla base della quale è possibile valutare la distanza tra due sottoinsiemi del piano (ovvero, nel nostro caso, due immagini).

Date due immagini $f, g$, definiamo la loro distanza $d(f, g)$, utilizzando la media quadratica, come

\[
d(f,s) = \sqrt{\int_{[0,1]^2} f(x,y) - g(x,y) \quad \text{d}x\text{d}y }
\]

La metrica ci fornisce una maniera di valutare la distanza tra due immagini pesando in maniera uniforme tutti i punti in esse contenuti.

\subsection*{Self-similarity debole}

A differenza di quanto accade quando si osserva un frattale vero e proprio, all'interno di immagini ``naturali'' non troviamo una \emph{self-similarity} forte: solitamente non abbiamo parti dell'immagine che sono simili all'immagine complessiva, bensì parti dell'immagine che sono simili ad altre parti dell'immagine. Un altro aspetto da considerare è quello della colorazione: due parti dell'immagine potrebbero essere simili nella composizione dei pixel, ma differenti per quanto riguarda la gradazione di grigio dei pixels che le compongono. 

I basilari IFS che abbiamo descritto in precedenza vanno leggermente complicati, nel contesto della compressione frattale delle immagini, in modo da accomodare i due aspetti qui sopra descritti. Come prima cosa, notiamo che al momento di definire le trasformazioni $w_i$, dovremo fare in modo che ad ogni trasformazione sia consentito di andare a toccare solo un particolare sottoinsieme del piano, in maniera da accomodare il requisito di poter rappresentare la \emph{self-similarity} debole (similarità tra parti e altre parti, e non con l'intera immagine). Come seconda cosa, alle mappe vanno aggiunti due parametri, \emph{contrasto} e \emph{luminosità}, che ci consentiranno di definire non solo trasformazioni  \emph{spaziali}, ma anche trasformazioni che vanno a coinvolgere la differenza di \emph{colorazione} (sempre su scala di grigi) tra due sottoinsiemi di piano.

Invece della classica trasformazione su $\mathbb{R}^2$ che ci aspetteremmo considerato il fatto che stiamo operando su funzioni $\mathbb{R}^2 \rightarrow \mathbb{R}$, definiamo le $w_i$ come trasformazioni su $\mathbb{R}^3$:

\[
w_i \begin{bmatrix} 
x \\
y \\
z
\end{bmatrix} = \begin{bmatrix}
a_i & b_i & 0 \\
c_i & d_i & 0 \\
0 & 0 & s_i \\
\end{bmatrix} \cdot \begin{bmatrix} 
x \\
y \\
z
\end{bmatrix} + \begin{bmatrix} 
e_i \\
f_i \\
o_i
\end{bmatrix}
\]

La trasformazione è formata da una componente \emph{spaziale}, ovvero

\[
v_i \begin{bmatrix} 
x \\
y \\
\end{bmatrix} = \begin{bmatrix}
a_i & b_i \\
c_i & d_i \\
\end{bmatrix} \cdot \begin{bmatrix} 
x \\
y \\
\end{bmatrix} + \begin{bmatrix} 
e_i \\
f_i \\
\end{bmatrix}
\]

e di due parametri aggiuntivi $s_i$ ed $o_i$, che agiscono rispettivamente come moltiplicatore e scala tramite somma sulla componente $z$ della funzione. Questi due parametri, che chiamiamo rispettivamente \emph{contrasto} e \emph{luminosità}, non influenzano in alcun modo le componenti spaziali della trasformazione, e ci consentono di definire trasformazioni sullo spazio di \emph{colore} dell'immagine (che, ricordiamo, è rappresentato nella funzione associata all'immagine come la componente $z$). 

Ricordando che l'immagine è rappresentata da una funzione $z = f(x,y)$, dove $x$ ed $y$ sono pixels e $z$ il grado di grigio dell'immagine \emph{grayscale}, una singola trasformazione $w_i$ viene applicata calcolando $w_i(f) = w_i(x, y, f(x,y))$. La parte spaziale di $w_i$ determina come una sotto-parte dell'immagine è mappata su altre sottoparti, mentre $s_i$ ed $o_i$ determinano contrasto e luminosità della trasformazione.

Il fatto che il mapping sia da effettuarsi da sottoinsiemi a sottoinsiemi dell'immagine è permesso dal fatto che le varie $w_i$ sono implicitamente definite in modo da operare su un sottoinsieme di $[0,1]^2$, che chiamiamo $D_i$, dando come risultato un sottoinsieme di $[0,1]^2$, che chiameremo $R_i$. In simboli, scriviamo che

\[
v_i(D_i) = R_i
\]

ovvero la componente spaziale della trasformazione ha dominio in sottoinsiemi del piano che chiamiamo $D_i$ e codominio in sottoinsiemi del piano che chiamiamo $R_i$.

Poiché richiediamo che $W(f)$, l'unione delle $w_i$, sia a sua volta un'immagine compatta, le trasformazioni devono soddisfare due proprietà basilari: prima di tutto gli $R_i$ devono partizionare completamente $[0,1]^2$, ovvero deve valere $\bigcup_i R_i = [0,1]^2$. Inoltre gli $R_i$ non devono sovrapporsi, ovvero deve valere $R_i \not= R_j$ se $i \not= j$. Queste due proprietà garantiscono che l'applicazione della mappa $W$ su una immagine $S$ risulti in una immagine $S'$, possibilmente differente, ma completa ed univoca.

Poiché la mappa $W$ è contrattiva solo se lo sono le trasformazioni $w_i$, è necessario scegliere accuratamente i parametri di queste ultime. Dato che la metrica di distanza $d$ che abbiamo definito sopra non prende in considerazione le direzioni $x$ ed $y$, ma soltanto la direzione $z$, per assicurare la contrattività delle $w_i$ è sufficiente fare attenzione al parametro di scala $s_i$. In particolare:

\begin{proprieta}
Le trasformazioni $w_i$ sono contrattive per $s_i < 1$
\end{proprieta}

\subsection*{Decoding}

A questo punto abbiamo tutti gli strumenti che servono per effettuare il \emph{decoding} di una immagine compressa utilizzando frattali: partendo  da una immagine qualunque, si applica ripetutamente la mappa $W$ fino a quando non si raggiunge il suo punto fisso $x_W$, che rappresenta il risultato dell'operazione di decodifica.

L'aspetto interessante (e complicato) della tecnica di compressione che stiamo descrivendo è però un altro: come fare, data una immagine $f$ da comprimere, a trovare un insieme di mappe $\{w_i\}_i$ tale che $f$ sia il punto fisso della loro unione ($W$)? Questa operazione, che rappresenta il nucleo delle tecniche di compressione tramite frattali, è l'argomento della prossima sezione.

\section{Encoding}

Come anticipato nella precedente sezione, per comprimere un'immagine $f$ è necessario trovare una mappa $W$ tale che 

\[
f = W(f)
\]

ovvero una mappa $W$ avente $f$ come attrattore. Ricordando la definizione di $W$, la proprietà richiesta diventa

\[
f = w_1(f) \cup w_2(f) \cup \dots \cup w_N(f)
\]

Per ottenere questo, dovremmo procedere con il partizionare l'immagine $f$ in tanti pezzi tali per cui, applicando le trasformazioni $\{w_i\}_i$, si otterrebbe l'immagine di partenza. Chiaramente, in generale, questa è una condizione troppo restrittiva: ottenere \emph{esattamente} l'immagine di partenza non è qualcosa che sia possibile sperare (a parte nei casi in cui si stia cercando di comprimere un'immagine frattale!).

Quello che facciamo in pratica è cercare delle trasformazioni che, applicate, ci restituiscano un'immagine \emph{differente}, diciamo $f'$, tale per cui la distanza con l'immagine di partenza, ovvero $d(f,f')$, è piccola. Operativamente, procediamo calcolando le $w_i$ con l'obbiettivo di minimizzare la distanza tra il pezzo di immagine che stiamo attualmente considerando e il pezzo di immagine ottenuto dopo l'applicazione della trasformazione. In formula, minimizziamo

\[
d\big(f \cap (R_i \times I), w_i(f)\big) 
\]

per tutti gli $i$. In termini di $R_i$ ed $D_i$ (i concreti pezzi di immagini su cui andremo ad operare), dobbiamo partizionare l'immagine $f$ in una collezione di pezzi $R_i$, e cercare da una seconda collezione $D_i$ dei pezzi tali per cui la mappa da $D_i$ ad $R_i$ comporta un errore (calcolato come distanza $d$) che sia piccolo.

\subsection*{Metrica}

Come abbiamo visto, la comparazione tra le due immagini avviene tramite la radice della media quadratica. L'utilizzo di questa metrica ci consente di calcolare i valori ottimali per $s_i$ e di $o_i$ in maniera diretta. In particolare, dati due quadrati contenenti $n$ valori di luminosità dei pixel $a_1, \dots, a_n$ per $D_i$ e $b_1, \dots, b_n$ per $R_i$, possiamo cercare i valori di $s$ e di $o$ che minimizzano la quantità:

\[
R = \sum_{i=1}^{n}{\left( s \cdot a_i + o - b_i \right) }
\]

Questa quantità ci fornisce i valori di contrasto e luminosità che fanno si che la trasformazione dai i valori di $a_i$  a quelli di $b_i$ abbia la minima distanza possibile. Il valore minimo di $R$ si ha quando le derivate parziali di $s$ e di $o$ si azzerano, ovvero quando

\[
s = \dfrac{ n \sum\limits_{i=1}^{n}{a_i b_i} - \sum\limits_{i=1}^{n}{a_i} \sum\limits_{i=1}^{n}{b_i} }
{n \sum\limits_{i=1}^{n}{a_i^2} - {\left( \sum\limits_{i=1}^{n}{a_i} \right)}^2 }
\]

e

\[
o = \frac{1}{n} \left( \sum\limits_{i=1}^{n}{b_i} - s \sum\limits_{i=1}^{n}{a_i} \right)
\]

A questo punto, avendo i valori ottimali di $s$ e di $o$, possiamo calcolare $R$ come:

\[
R = \frac{1}{n} \left[ \sum\limits_{i=1}^{n}{b_i^2} 
+ s \left( s \sum\limits_{i=1}^{n}{a_i^2} - 2 \sum\limits_{i=1}^{n}{a_i b_i} + 2o \sum\limits_{i=1}^{n}{a_i}  \right) 
+ o \left( no - 2 \sum\limits_{i=1}^{n}{b_i} \right)  \right]
\]

la distanza tra le due immagini $A$ e $B$ è ora equivalente a $\sqrt{R}$.

\subsection*{Partizionare le immagini}

Una questione che è necessario innanzitutto risolvere è quella relativa alla scelta delle collezioni $R_i$ e $D_i$. 

La maniera più ovvia di partizionare $f$ è quella di dividerla in quadrati di una dimensione predeterminata, ma questa scelta presenta dei problemi. Nel caso all'interno dell'immagine da trattare non vi sia una uniforme distribuzione della ``complessità dei dettagli'' (succede, ad esempio, per un ritratto di persona, che avrà un alto livello di complessità nella zona dove si trova il viso del soggetto e un basso livello di complessità ai bordi, dove si vede un muro di colore uniforme che fa da sfondo alla fotografia) una divisione uniforme andrà a penalizzare le zone con maggior presenza di dettagli, e a sprecare inutilmente blocchi (che saranno tutti uguali) per lo sfondo.

Un metodo di partizionamento migliore è quello basato sui \emph{quadtrees}. Si divide iniziamente l'immagine in 4 parti, e si controlla il livello di fedeltà dei sotto-quadrati rispetto all'immagine orignale. Se il livello di fedeltà è entro un limite $e_c$ prefissato, il blocco entra a far parte dell'insieme degli $R_i$. Altrimenti lo si partiziona in 4 parti e si ri-applica nuovamente, ricorsivamente, il procedimento appena descritto.

In genere è anche conveniente, nel contesto della compressione di immagini, scegliere due parametri $Q_{\text{max}}$ e $Q_{\text{min}}$ che definiscono rispettivamente la grandezza massima e minima dei blocchi $R_i$. Nel caso un blocco abbia dimensioni superiori a $Q_{\text{max}}$, lo si partiziona a prescindere dalla complessità interna; nel caso un blocco avente dimensioni $Q_{\text{min}}$ si cessa di partizionarlo, a prescindere dal livello di uniformità interna. Questi due parametri consentono di avere un maggior controllo sulle dimensioni dei blocchi $R_i$, e soprattutto sulla cardinalità dell'insieme degli $R_i$, che influenza pesantemente il tempo di esecuzione dell'operazione di codifica.

L'immagine sottostante fornisce un esempio del tipo di partizione che si può ottenere utilizzando un \emph{quadtree}. Si nota che nei punti in cui l'immagine è uniforme i blocchi sono di dimensioni maggiori, mentre nei punti ricchi di dettagli (il viso, la piuma del cappello) la suddivisione è tanto fine quanto lo consente il parametro $Q_{\text{min}}$.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.5]{images/lena.pdf} 
\includegraphics[scale=0.5]{images/quadlena.pdf} 
\caption{Quadtree su Lena, $Q_{\text{min}} = 8$, $Q_{\text{max}} = 64$, $e_c = 0.4$}
\end{figure}

Oltre al partizionamento con \emph{quadtree}, esistono altri metodi applicabili in questo contesto, ad esempio il metodo di partizionamento HV ed il metodo di partizionamento triangolare, che va a generare sottoimmagini non quadrate e può essere quindi vantaggioso nei casi in cui l'immagine di partenza contenga un gran numero di linee oblique (che non sono facilmente coperte da metodi di partizionamento basati su quadrati).

\subsection*{L'algoritmo}

Abbiamo ora a disposizione tutti gli elementi che ci servono per descrivere ad alto livello il funzionamento dell'algoritmo di codifica frattale. Lo riportiamo di seguito:

\begin{framed}
\begin{algorithmic}
\Procedure{Encode}{$e_c$, $r_{\text{min}}$}
\State $R_1 \gets [0,1]^2$
\State $R \gets R \cup R_1$
\State Segna $R_1$ come non coperto
\While{$\exists R_i \in R$ non coperto}
	\State $D_i, w_i \gets$ \Call{bestcover}{$R_i$}  
	\If{$d\big(f \cap (R_i \times I), w_i(f)\big) < e_c$ OR $ \text{size}(R_i) \leq r_{\text{min}}$}
		\State Segna $R_i$ come coperto
		\State $W \gets W \cup w_i$
	\Else	
		\State Partiziona $R_i$ in 4 parti $R_a, R_b R_c, R_d$ 
		\State $R \gets R \setminus R_i$
		\State $R \gets R \cup \{R_a, R_b, R_c, R_d\}$
		\State Segna $R_{\{a,b,c,d\}}$ come non coperti
	\EndIf
\EndWhile
\EndProcedure
\end{algorithmic}
\end{framed}

La procededura \textproc{bestcover} prende come input una sottimmagine $R_i$, e ritorna la sottoimmagine $D_i$ e la rispettiva trasformazione $w_i$ che coprono meglio $R_i$.

\begin{framed}
\begin{algorithmic}
\Procedure{bestcover}{$R_i$}
\State $score \gets \infty$
\State $d, w \gets$, NULL, NULL
\ForAll{$D_i \in D$}
	\State $w_{\text{temp}}, s \gets$ \Call{score}{$D_i, R_i$}
	\If{$s < score$}
		\State $w \gets w_{\text{temp}}$
		\State $score \gets s$
		\State $d \gets D_i$
	\EndIf
\EndFor \\
$~~~~$\Return $d, w$
\EndProcedure
\end{algorithmic}
\end{framed}

La procedura \textproc{score} restituisce una trasformazione $w_i$ ed uno $score$ che indica il livello di somiglianza tra la sottoimmagine di partenza $R_i$ e la sottoimmagine calcolata $D_i$.

\chapter{Aspetti Pratici e implementazione}

In questo capitolo forniamo un'implementazione didattica dell'algoritmo di compressione usando frattali per permettere di comprenderne gli aspetti pratici. Il codice è stato scritto in linguaggio MATLAB ed è disponibile all'indirizzo \url{http://github.com/luca-dex/shiny-octo-dubstep}.

\section{Creazione del Dominio}

Il primo passo dell'algoritmo è quello di andare a creare, partendo dall'immagine da comprimere, il dominio $D$. Questa operazione è descritta nel frammento di codice riportato di seguito.

\begin{minted}[linenos=true]{matlab}
function [ d, d2 ] = domains( image, range_sizes, l )
if nargin < 3
    l = 2;
end
d = {1000,2};
dim = length(image);
index = 1;
counter = 1;
range_sizes = sort(range_sizes, 'descend');
for size = range_sizes
    step = size / l;
    for i = 1:step:(dim-size)
        for j = 1:step:(dim-size)
            counter = counter + 1;
            imm = image(i:i+size-1, j:j+size-1);
            if check_equals(d, imm, index-1)
                continue
            end
            d(index,1) = {imm};
            d(index,2) = {[i j size]};
            index = index + 1;
        end
    end
end
\end{minted}

Inizialmente (righe 2 - 4) viene definito il passo di sovrapposizione tra le immagini del dominio; di default la sovrapposizione è metà della dimensione dell'immagine. Successivamente (riga 10) si itera su ogni dimensione che si vuole assegnare al dominio e per ognuna di si va a definire lo step di sovrapposizione come \texttt{size / l} (riga 11). I passi successivi (righe 12 e 13) sono quello di andare ad individuare tutti gli inizi di sottoimmagine del dominio (angolo in alto a sinistra dell'immagine), dato il valore di \texttt{step}, e quello prendere l'immagine di dimensione \texttt{size} (riga 15). Se questa sottoimmagine non è ancora presente nel dominio (riga 16), allora la si memorizza (riga 19), unitamente alle sue coordinate e alla sua dimensione (riga 20).

A questo punto abbiamo creato il dominio $D$ che andremo ad utilizzare nei prossimi passi dell'algoritmo. Per comodità, siccome durante i confronti ogni immagine nel dominio viene dimezzata, al termine di questa procedura provvederemo a salvare una copia di ogni immagine del dominio di dimensioni dimezzate con opportuna trasformazione lineare.

\section{Encoding}

Ora si cerca di trovare una copertura ottimale per ogni partizione dell'immagine.

\begin{minted}[linenos=true]{matlab}
function [ partial_enc ] = 
    qtfunction(img, pos, size, split_t, min_size, max_size, doms, min_rms)

    global img_copy;
    x = pos(1);
    y = pos(2);
    partial_enc = [];

    if size/2 > max_size
        a = qtfunction(img, [x y], size/2, split_t, 
            min_size, max_size, doms, min_rms);
        b = qtfunction(img, [x+size/2 y], size/2, split_t, 
            min_size, max_size, doms, min_rms);
        c = qtfunction(img, [x y+size/2], size/2, split_t, 
            min_size, max_size, doms, min_rms);
        d = qtfunction(img, [x+size/2 y+size/2], size/2, split_t, 
            min_size, max_size, doms, min_rms);
        partial_enc = [a; b; c; d;];
        return
    end

    rms = repmat(+Inf, [1 4]);
    ts = zeros(1, 4);
    doms_ind = zeros(1, 4);

    for i = 1:length(doms)
        d = doms{i,1};
        if length(d) ~= size/2
            continue
        end
        
        if rms(1) > min_rms
            [r, t] = sup_dist(img(x:(x + size/2 -1), 
                                  y:(y + size/2 -1)), d);
            if r < rms(1)
                rms(1) = r;
                ts(1) = t;
                doms_ind(1) = i;
            end
        end
        
        if rms(2) > min_rms
            [r, t] = sup_dist(img((x + size/2):(x+size-1), 
                                   y:(y + size/2 -1)), d);
            if r < rms(2)
                rms(2) = r;
                ts(2) = t;
                doms_ind(2) = i;
            end
        end
        
        if rms(3) > min_rms
            [r, t] = sup_dist(img(x:(x + size/2 - 1), 
                                 (y + size/2):(y+size-1)), d);
            if r < rms(3)
                rms(3) = r;
                ts(3) = t;
                doms_ind(3) = i;
            end
        end
        
        if rms(4) > min_rms
            [r, t] = sup_dist(img((x + size/2):(x+size-1) , 
                                  (y + size/2):(y+size-1)) , d);
            if r < rms(4)
                rms(4) = r;
                ts(4) = t;
                doms_ind(4) = i;
            end
        end        
    end

    if rms(1) > split_t && size/2 > min_size
        partial_enc = [partial_enc; qtfunction(img, [x y], size/2,
             split_t, min_size, max_size, doms, min_rms)];
    else
        img1 = img(x:(x + size/2 -1), y:(y + size/2 -1));
        [s, o] = least_squared_params(img1, doms{doms_ind(1),1});
        partial_enc = [partial_enc; 
            [x y size/2 doms{doms_ind(1),2} ts(1) s o]];
    end

    if rms(2) > split_t && size/2 > min_size
        partial_enc = [partial_enc; qtfunction(img, [x+size/2 y], size/2, 
            split_t, min_size, max_size, doms, min_rms)];
    else
        img1 = img((x + size/2):(x+size-1), y:(y + size/2 -1));
        [s, o] = least_squared_params(img1, doms{doms_ind(2),1});
        partial_enc = [partial_enc; 
            [x+size/2 y size/2 doms{doms_ind(2),2} ts(2) s o]];
    end

    if rms(3) > split_t && size/2 > min_size
        partial_enc = [partial_enc; qtfunction(img, [x y+size/2], size/2, 
            split_t, min_size, max_size, doms, min_rms)];
    else
        img1 = img(x:(x + size/2 - 1), (y + size/2):(y+size-1));
        [s, o] = least_squared_params(img1, doms{doms_ind(3),1});
        partial_enc = [partial_enc; 
            [x y+size/2 size/2, doms{doms_ind(3),2} ts(3) s o]];
    end

    if rms(4) > split_t && size/2 > min_size
        partial_enc = [partial_enc; qtfunction(img, [x+size/2 y+size/2], size/2, 
            split_t, min_size, max_size, doms, min_rms)];
    else
        img1 = img((x + size/2):(x+size-1) , (y + size/2):(y+size-1));
        [s, o] = least_squared_params(img1, doms{doms_ind(4),1});
        partial_enc = [partial_enc; 
            [x+size/2 y+size/2 size/2, doms{doms_ind(4),2} ts(4) s o]];
    end
end
\end{minted}

Come prima operazione si valuta se il partizionamento produce sottoimmagini sufficientemente piccole (riga 9) e, nel caso questo non avvenga, si procede a dividere in 4 parti l'immagine considerata e ad applicare ricorsivamente la procedura (righe 10 - 19). 

Successivamente, per ognuna della quattro sottoimmagini generate tramite il partizionamento con \emph{quadtree}, vengono calcolati i valore della distanza $d$ e della rotazione dell'immagine del dominio. Ad esempio per la sottoimmagine in alto a sinistra la procedura parte col considerare tutti gli elementi del dominio, (riga 26) e per ognuno, tramite la funzione \texttt{sup\_dist} (riga 33) verificare se viene trovato un valore di distanza $d$ minore di quelli calcolati fino a quel momento. Per fare questa operazione viene considerata anche ogni possibile roto-traslazione dell'immagine stessa. Se il valore è effettivamente minore, questo viene memorizzato (riga 36) unitamente alle indicazioni sulla rotazione e all'indice di posizione dell'elemento del dominio (righe 37 e 38). Questa operazione viene ripetuta per tutte e quattro le sottoimmagini.

Ora che per ogni sottoimmagine è stata individuata la migliore copertura si passa a verificare se questa effettivamente soddisfava il valore di threshold voluto e di dimensioni minime. In caso positivo si memorizzano tutti i valori necessari, in caso contrario si applica ricorsivamente la funzione al quarto di immagine. Ad esempio per la sottoimmagine in alto a sinistra la procedura parte con il verificare se le soglie di threshold e dimensione sono rispettate (riga 73) e in caso negativo si riapplica la procedura a questo quarto di immagine (righe 74 - 75). Nel caso in cui i valori di soglia siano rispettati invece si calcolano i valori di \texttt{s} e di \texttt{o} (riga 78) e si memorizza il tutto nella mappa $W$ (righe 79 e 80).  Questa operazione viene ripetuta per tutte e quattro le sottoimmagini.

A questo punto l'encoding è terminato, in quanto si ha a disposizione la mappa $W$ che, come abbiamo visto precedentemente, contiene tutte le informazioni che servono per trasformare un immagine qualsiasi nell'immagine di partenza.

\section{Metrica}

Nel precedente frammento di codice è stata introdotta la funzione \texttt{sup\_dist} per il calcolo della distanza tra immagine nel dominio e immagine proveniente dal \emph{quadtree}, di seguito è riportato il funzionamento effettivo di questa funzione, che rispecchia le equazioni viste in precedenza per il calcolo della distanza basandosi sui valori ottimali di $s$ e $o$.

\begin{minted}[linenos=true]{matlab}
function [ rms, transf ] = sup_dist( img1, img2 )
    rms_arr = zeros(1,8);

    for i = 1:8
        rms_arr(i) = dsh(img1, rotate_image(img2, i));
    end

    transf = find(rms_arr - min(rms_arr) == 0, 1);
    rms = rms_arr(transf);
end

function [s, o] = least_squared_params(img1, img2)
    n = length(img1)^2;
    a = single(reshape(img2, [1, n]));
    b = single(reshape(img1, [1, n]));

    s = ( n * dot(a, b) - sum(a)*sum(b) ) / ( n * sum(a.^2) - sum(a)^2 );
    s = min(s, 1);
    o = ( sum(b) - s*sum(a) ) / n;
end

function [ rms ] = dsh(img1, img2)
    [s, o] = least_squared_params(img1, img2);

    n = length(img1)^2;
    a = single(reshape(img2, [1, n]));
    b = single(reshape(img1, [1, n]));

    rms = sqrt(( sum(b.^2) + s * (s*sum(a.^2) - 2*dot(a,b) 
        + 2*o*sum(a)) + o*(n*o - 2*sum(b)) ) / n);
end
\end{minted}

La funzione principale è \texttt{sup\_dist}, che si occupa di effettuare il confronto tra la sottoimmagine presa in cosiderazione e tutte le possibili 8 rototraslazioni dell'elemento del dominio (righe 4 - 8). Questa funzione restituisce poi il valore della distanza e la rotazione, rappresentata da una mappa di valori da 1 a 8, (righe 10 e 11).

La seconda funzione, \texttt{least\_squared\_params}, si occupa, date due immagini, di trovare i valori di $s$ e di $o$ secondo le equazioni viste nel precedente capitolo (righe 17 - 19).

La terza funzione, \texttt{dsh}, si occupa, date due immagini e calcolati i valori di $s$ e di $o$ tramite la precedente funzione, di calcolare il valore della distanza (righe 29 e 30).

\section{Output dell'esecuzione}

Dopo aver introdotto gli algoritmi che abbiamo sviluppato vediamo brevemente quale è il risultato dell'encoding e del deconding. Prendiamo ad esempio un'immagine digitale, riportata in Figura \ref{fig:girl}, con il viso di una ragazza. L'immagine è in formato BITMAP a 8 bits in scala di grigi e ha dimensioni $512 \times 512$ pixel. Abbiamo scelto questa immagine perché ha delle vaste zone di colore uniforme, come il viso o lo sfondo, e altre zone estremamente complesse, come quelle coperte dai capelli. Questi dettagli ci hanno permesso di valutare la bontà della nostra implementazione.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.4]{images/girl.pdf} 
\caption{girl grayscale, $128 \times 128$ pixels.}
\label{fig:girl}
\end{figure}

L'immagine è stata codificata con i seguenti parametri:

\begin{itemize}
\item \texttt{dom\_range = [4, 8, 16, 32]} 
\item \texttt{l = 2}
\item \texttt{min\_rms = 4}
\item \texttt{min\_rms = 10}
\end{itemize}

L'output prodotto dal nostro algoritmo è una tabella di $36760 \times 9$ elementi, le cui dimensioni complessiva sono di circa 1MB. Il tempo di encoding è stato di circa 10 ore su una macchina con processore Pentium  \emph{i7 @ 2.4GHz} e 4 GB di RAM. Non applicando nessuna ottimizzazione o compressione della tabella stessa il peso rimane piuttosto alto. 

Di seguito, in Figura \ref{fig:girls}, riportiamo la sequenza di immagini successive che si ottengono durante l'iterazione della procedura di decoding (ovvero l'applicazione della funzione $W$ che definisce l'\emph{iterated system} associato all'immagine di partenza). Ad ogni passo vengono applicate le trasformazioni descritte nella tabella prodotta, a partire da un'immagine completamente nera. Sono stati eseguiti complessivamente 12 step, ma già dal decimo in poi si può notare, anche a occhio, come le variazioni siano minime. Il risultato finale (quello raffigurato nell'ultima immagine) presenta dettaglio massimo che siamo riusciti ad ottenere con l'implementazione MATLAB qui sopra descritta. L'immagine non è stata ricostruita con un grande livello di dettaglio, ma dobbiamo osservare che la figura di partenza (quella scelta per testare l'implementazione) era estremamente complessa.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.35]{images/girl01} 
\includegraphics[scale=0.35]{images/girl02} 
\includegraphics[scale=0.35]{images/girl03} 
\includegraphics[scale=0.35]{images/girl04}
\includegraphics[scale=0.35]{images/girl05}
\includegraphics[scale=0.35]{images/girl06}
\includegraphics[scale=0.35]{images/girl07}
\includegraphics[scale=0.35]{images/girl08}
\includegraphics[scale=0.35]{images/girl09}
\includegraphics[scale=0.35]{images/girl10}
\includegraphics[scale=0.35]{images/girl11}
\includegraphics[scale=0.35]{images/girl12}         
\caption{12 step di decoding per l'immagine della ragazza.}
\label{fig:girls}
\end{figure}



\chapter{Test, benchmarks}

Come già sottolineato nell'introduzione, un aspetto importante da considerare durante la trattazione di tecniche di compressione ``non ortodosse'' è quello relativo alla loro effettiva usabilità in scenari realistici. È per questo motivo molto importante, una volta terminata la trattazione degli aspetti teorici della tecnica, effettuare una serie di test e benchmarks che consentano di effettuare una comparazione (che sia il più possibile oggettiva) tra i risultati ottenuti con la tecnica di compressione descritta e quelli ottenibili utilizzando invece una delle tecniche di compressione tra quelle più comunemente utilizzate.

Poiché l'implementazione MATLAB descritta nel precedente capitolo è stata sviluppata esclusivamente per fini ``didattici'', e pertanto senza che venisse posta particolare attenzione ad aspetti quali effettiva usabilità in contesti reali e prestazioni del codice su immagini di dimensioni realistiche, abbiamo scelto di effettuare i nostri test utilizzando una libreria di compressione basata su frattali che fosse, oltre che più flessibile, anche più performante del codice da noi sviluppato. La nostra scelta è ricaduta su \emph{Fiasco} \cite{fiasco} \cite{IEEE} \cite{ULL}, una libreria \emph{open source} di compressione frattale implementata in C.

Dato che la compressione tramite frattali è inerentemente \emph{lossy}, la scelta naturale per il formato con cui effettuare la comparazione è rappresentata dallo standard JPEG\cite{jpeg}. Sono stati effettuati test di due differenti tipi: una prima batteria di test pensata per valutare la capacità delle due tecniche di compressione di gestire immagini di varie dimensioni (anche molto grandi), anche valutando i tempi di codifica e decodifica, ed una seconda batteria di test in cui si è cercato di effettuare una comparazione  delle qualità delle immagini decompresse. 

\section{ Efficienza ed efficacia della codifica }

Per valutare efficienza (ovvero la rapidità della codifica) ed efficacia (ovvero i rapporti di compressione ottenuti) della compressione frattale e della compressione JPEG, sono state utilizzate sette versioni, differenti in dimensioni, di una immagine campione raffigurante un paesaggio naturale. Nella tabella seguente sono riportati i nomi, le dimensioni ed il peso delle immagini utilizzate. Tutte le immagini sono fotografie in \emph{grayscale}, salvate come file in formato \texttt{.pgm}.

\begin{figure}[!ht]
\centering
\begin{tabular}{c||c|c}
Immagine & Dimensioni & Peso \\ 
\hline 
\texttt{california\_coast\_320} & 320 $\times$ 240 & 0.07 MB \\
\hline 
\texttt{california\_coast\_640} & 640 $\times$ 480 & 0.30 MB \\
\hline 
\texttt{california\_coast\_800} & 800 $\times$ 600 & 0.48 MB \\
\hline 
\texttt{california\_coast\_1200} & 1200 $\times$ 900 & 1.10 MB \\
\hline 
\texttt{california\_coast\_1600} & 1600 $\times$ 1200 & 1.90 MB \\
\hline 
\texttt{california\_coast\_2400} & 2400 $\times$ 1800 & 4.30 MB \\
\hline 
\texttt{california\_coast\_3648} & 3648 $\times$ 2736 & 10.0 MB \\
\end{tabular} 
\caption{Le immagini di test}
\end{figure}

In un primo test abbiamo cercato di valutare la effettiva capacità delle due librerie di comprimere le immagini di test, e i rapporti di compressione ottenuti, lasciando in un primo momento da parte la valutazione dell'efficienza dell'operazione di codifica (ovvero il tempo impiegato per comprimere l'immagine). I risultati del test sono riportati in tabella

\begin{figure}[!ht]
\centering
\begin{tabular}{c||cc|cc}
Immagine & \multicolumn{2}{c|}{JPEG} & \multicolumn{2}{c}{Fiasco} \\ 
\hline 
 & \tiny{Peso} & \tiny{Compressione} & \tiny{Peso} & \tiny{Compressione} \\ 
\texttt{california\_coast\_320} & 026.5 kB & 2.64x & 02.7 kB & 25.9x \\
\texttt{california\_coast\_640} & 100.9 kB & 2.97x & 10.5 kB & 28.5x \\
\texttt{california\_coast\_800} & 147.3 kB & 3.25x & 16.3 kB & 29.4x \\
\texttt{california\_coast\_1200} & 330.4 kB & 3.32x & \multicolumn{2}{c}{\nope} \\
\texttt{california\_coast\_1600} & 515.5 kB & 3.68x & \multicolumn{2}{c}{\nope} \\
\texttt{california\_coast\_2400} & 1.00 MB & 4.30x & \multicolumn{2}{c}{\nope} \\
\texttt{california\_coast\_3648} & 1.90 MB & 5.26x & \multicolumn{2}{c}{\nope} \\
\end{tabular} 
\caption{Pesi e rapporti di compressione delle immagini codificate}
\end{figure}

Mentre la libreria JPEG è in grado di comprimere senza nessuna difficoltà le immagini utilizzate per il test, Fiasco fallisce sulle ultime 4 immagini con un \texttt{Maximum number of states reached!} error. Considerando che il primo file che Fiasco non riesce a trattare è una modesta immagine $1200 \times 900$ del peso di 1.1 MB, questo test rende abbastanza evidente come la compressione tramite frattali sia di fatto eccessivamente costosa (da un punto di vista computazionale) per permetterne l'utilizzo con immagini ad alta risoluzione. 

D'altra parte, sulle immagini che entrambe le librerie hanno potuto comprimere, appare evidente che la compressione tramite frattali consente di ottenere rapporti di compressione molto competitivi (un ordine di grandezza meglio del JPEG in questo caso). Va tuttavia sottolineato che il fattore di compressione andrà valutato anche sulla base dei tempi di codifica e della qualità dell'immagine ricavata successivamente, in fase di decompressione.

I tempi di compressione sono riportati nella tabella seguente:

\begin{figure}[!ht]
\centering
\begin{tabular}{c||cc|c}
Immagine & JPEG & Fiasco & Rapporto \\ 
\hline 
\texttt{california\_coast\_320} & 0.006s & 0.549s & 91.5x\\ 
\hline 
\texttt{california\_coast\_640} & 0.010s & 8.620s & 861x \\
\hline 
\texttt{california\_coast\_800} & 0.016s & 18.51s & 1156x \\
\hline 
\texttt{california\_coast\_1200} & 0.028s & \nope & -- \\
\hline 
\texttt{california\_coast\_1600} & 0.042s & \nope & -- \\
\hline
\texttt{california\_coast\_2400} & 0.087s & \nope & -- \\
\hline 
\texttt{california\_coast\_3648} & 0.183s & \nope & -- \\
\end{tabular} 
\caption{I tempi di codifica}
\end{figure}

Appare ora evidente il motivo per cui Fiasco ha rinunciato a comprimere le immagini più grandi: l'operazione di codifica è estremamente costosa, e i tempi di codifica vanno peggiorando esponenzialmente. JPEG comprime invece tutte le immagini testate in tempi molto rapidi.

\section{ Qualità delle immagini }

Non è facile, in generale, valutare in maniera oggettiva la qualità di due immagini compresse con una tecnica \emph{lossy} e successivamente decompresse. In questo caso, tuttavia, la differenza tra le immagini ricavate da JPEG e Fiasco è significativa, e visibile ad occhio nudo.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.25]{images/california-coast-jpeg.png} 
\includegraphics[scale=0.25]{images/california-coast-fiasco.png} 
\caption{ Da JPEG e da Fiasco, rispettivamente, dopo la decompressione }
\end{figure}

Andando a zoomare su un particolare dell'immagine, appare evidente come il rapporto di compressione ottenuto da Fiasco sia ottenuto al costo di una grossa perdita di dettaglio. Se avessimo deciso di codificare le immagini JPEG con una minore qualità (controllabile in fase di encoding tramite un parametro standard), probabilmente anche queste ultime avrebbero presentato un minor livello di dettaglio, ma il rapporto di compressione sarebbe aumentato notevolmente. Per quanto concerne questo test, abbiamo deciso di codificare le immagini in alta qualità, lasciando il parametro di input al valore standard applicato dalle librerie comunemente utilizzate.

\begin{figure}[!ht]
  \centering
    \begin{subfigure}[t]{0.47\textwidth}
        \includegraphics[width=\textwidth]{images/california-coast-jpeg-detail.png}
    \end{subfigure}
    \begin{subfigure}[t]{0.47\textwidth}
        \includegraphics[width=\textwidth]{images/california-coast-fiasco-detail.png}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.47\textwidth}
    \includegraphics[width=\textwidth]{images/california-coast-jpeg-detail2.png}
    \end{subfigure}
    \begin{subfigure}[b]{0.47\textwidth}
        \includegraphics[width=\textwidth]{images/california-coast-fiasco-detail2.png}
    \end{subfigure}
    \caption{ Da JPEG e da Fiasco, rispettivamente, dopo la decompressione (dettaglio)}
\end{figure}

\FloatBarrier

\section{Conclusioni}

In questo capitolo abbiamo confrontato efficienza, efficacia e risultato finale della codifica di immagini tramite frattali e della codifica tramite lo standard JPEG. Sulle immagini che sono effettivamente alla portata di un metodo di compressione frattale, Fiasco consente di effettuare una compressione di circa un ordine di grandezza migliore di quella garantita da JPEG. Nonostante la qualità finale delle immagini dopo la decodifica sia non eccellente (rispetto a quella JPEG), l'aspetto delle immagini ricostruite è buono, soprattutto considerando il rapporto di compressione raggiunto. Un'osservazione attenta dei particolari delle immagini rivela una buona perdita di qualità, ma le immagini, nel loro complesso, non presentano artefatti troppo evidenti.

Il costo computazionale del processo di codifica è senza dubbio il punto debole delle tecniche di compressione frattale. Mentre il tempo necessario per la compressione JPEG scala in maniera lineare con le dimensioni dell'immagine, quello impiegato da Fiasco aumenta in maniera esponenziale all'aumentare delle dimensioni, arrivando ad essere di 3 ordini di grandezza peggiore per un'immagine dalle (modeste) dimensioni di 1200 $\times$ 900. Tale inefficienza previene inoltre l'utilizzo della tecnica con immagini in alta definizione.

\appendix

\chapter{Tutorial per l'esecuzione del codice sorgente}

In questa appendice diamo una breve descrizione di come utilizzare il codice sorgente con cui sono stati realizzati gli esempi e i bechmarks utilizzati nel corso dell'esposizione. 

Per l'esecuzione del codice MATLAB è necessario aver installata l'\emph{Image Processing Toolbox}\footnote{\url{mathworks.com/products/image/}}.

Per l'esecuzione dei benchmarks è necessario che siano installati sul sistema \emph{ImageMagick}\footnote{\url{www.imagemagick.org/}}, libreria per la manipolazione di immagini utilizzata per effettuare la compressione in formato JPEG, e Fiasco\footnote{\url{github.com/l-tamas/Fiasco}}, libreria sperimentale per la compressione di immagini utilizzando FIC.

\noindent La prima cosa da fare è clonare il repository che contiene tutti i sorgenti:
\begin{verbatim}
git clone https://github.com/luca-dex/shiny-octo-dubstep
\end{verbatim}

Il contenuto della cartella è organizzato nel seguente modo:

\begin{itemize}
\item \texttt{src/} contiene i sorgenti dell'algoritmo implementato in MATLAB
\item \texttt{benchmarks} contiene gli script per eseguire i benchmarks
\item \texttt{doc/} contiene il sorgente da cui è stato realizzato questo documento
\item \texttt{workspace/} Ccontiene esempi di immagini compresse realizzate con l'algoritmo implementato in MATLAB
\end{itemize}

\section{Implementazione MATLAB}

Il codice MATLAB è progettato per essere eseguito in maniera parallela su una macchina dotata di quattro cores. La prima parte del codice effettua l'encoding dell'immagine. L'impostazione di tutti i parametri iniziali avviene all'interno del file \texttt{main.m}. I parametri che è possibile configurare sono:

\begin{itemize}
\item \texttt{im}: Path dell'immagine da comprimere, che deve essere quadrata ed in formato BMP
\item \texttt{dom\_range}: Dimensione degli elementi che verranno salvati nel dominio. Devono essere divisori della lunghezza del lato dell'immagine
\item \texttt{l}: Parametro di sovrapposizione. Il default è 2
\item \texttt{min\_rms}: La soglia di errore oltre la quale si accetta la copertura selezionata
\item \texttt{max\_range}: La soglia di errore oltre la quale si rifiuta la copertura selezionata e si riapplica la suddivisione in 4 parti 
\item \texttt{output}: Path dell'output dell'algoritmo (workspace MATLAB).
\end{itemize}

Una volta che tutti i parametri sono stati configurati, l'esecuzione può essere lanciata. Il tempo di calcolo è molto alto, poiché il codice non è stato sviluppato in maniera ottimizzata. È consigliato non eccedere con la dimensione delle immagini (512 $\times$ 512 è il limite oltre il quale il codice non è stato testato).

Una volta che l'immagine è stata compressa, può essere ricostruita con la funzione \texttt{decode\_all}. Dentro a questa funzione deve essere configurato il parametro \texttt{workspace}, con il path del workspace salvato dalla funzione precedente. Questa funzione mostra per prima cosa l'immagine originale e, ogni volta che viene effettuato un click del mouse all'interno dell'immagine, mostra lo step di ricostruzione successivo.

\section{Benchmarks}

La \emph{repository} contiene anche gli script bash che sono stati utilizzati per i test (cartella \texttt{benchmarks}). Le immagini di test sono contenute nella sotto-cartella denominata \texttt{images}. Per lanciare i test, è necessario eseguire i seguenti script, in ordine:

\begin{enumerate}
\item \texttt{convert2pgm.sh}, che converte le immagini di test in formato \texttt{pgm}, l'unico supportato da Fiasco
\item \texttt{encode2fiasco.sh}, che comprime le immagini \texttt{pgm} create al passo precedente utilizzando Fiasco
\item \texttt{encode2jpeg.sh}, che comprile le immagini di test utilizzando JPEG
\item \texttt{decodefiasco.sh}, che decodifica e decomprime le immagini compresse tramite frattali
\end{enumerate}

Tutti i risultati delle computazioni vengono salvati in una propria cartella, che i vari script si occupano di creare e popolare. La velocità  delle operazioni di compressione è misurata in automatico dai relativi script utilizzando il comando UNIX \texttt{time}.

Gli script sono stati sviluppati, testati ed eseguiti in ambiente Linux.

\begin{thebibliography}{9}

\bibitem{fisher}
Yuval Fisher (Ed.)
\textit{Fractal Image Compression: Theory and Application}
Springer-Verlag, London, UK 1995.

\bibitem{barnsley}
Michael Barnsley.
\textit{Fractals Everywhere.} 
Academic Press Prof., Inc., San Diego, CA, USA 1988.

\bibitem{fiasco}
Ullrich Hafner
\textit{Fractal Image And Sequence COdec}. 
\url{https://github.com/l-tamas/Fiasco}.
 
\bibitem{IEEE} 
Ullrich Hafner, Juergen Albert, Stefan Frank, and Michael Unger
\textit{Weighted Finite Automata for Video Compression}
IEEE Journal on Selected Areas In Communications, January 1998.

\bibitem{ULL}
Ullrich  Hafner
\textit{Low Bit-Rate Image and Video Coding with Weighted Finite Automata}
Ph.D. thesis, Mensch \& Buch Verlag, ISBN 3-89820-002-7, October 1999.

\bibitem{jpeg}
IEEE
\textit{The JPEG Standard - \texttt{ISO/IEC 10918}}

\end{thebibliography} 




\end{document}
